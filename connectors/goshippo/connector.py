"""Goshippo Connector for syncing shipment data from the Goshippo API.
This connector demonstrates how to fetch shipment data from Goshippo and upsert it into destination using the Fivetran Connector SDK.
See the Technical Reference documentation (https://fivetran.com/docs/connectors/connector-sdk/technical-reference#update)
and the Best Practices documentation (https://fivetran.com/docs/connectors/connector-sdk/best-practices) for details
"""

# For reading configuration from a JSON file
import json

# For time-related operations and delays
import time

# For making HTTP API requests
import requests

# Import required classes from fivetran_connector_sdk
from fivetran_connector_sdk import Connector

# For enabling Logs in your connector code
from fivetran_connector_sdk import Logging as log

# For supporting Data operations like Upsert(), Update(), Delete() and checkpoint()
from fivetran_connector_sdk import Operations as op

__BASE_URL = "https://api.goshippo.com"
__MAX_RETRIES = 3
__BASE_DELAY_SECONDS = 2
__REQUEST_TIMEOUT_SECONDS = 30
__CHECKPOINT_INTERVAL = 100
__PAGE_SIZE = 25
__MAX_PAGE_SIZE = 100


def schema(configuration: dict):
    """
    Define the schema function which lets you configure the schema your connector delivers.
    See the technical reference documentation for more details on the schema function:
    https://fivetran.com/docs/connectors/connector-sdk/technical-reference#schema
    Args:
        configuration: a dictionary that holds the configuration settings for the connector.
    """
    return [
        {"table": "shipments", "primary_key": ["object_id"]},
        {"table": "shipment_rates", "primary_key": ["rate_object_id", "shipment_object_id"]},
        {"table": "shipment_parcels", "primary_key": ["parcel_object_id", "shipment_object_id"]},
        {"table": "shipment_messages", "primary_key": ["message_id"]},
    ]


def update(configuration: dict, state: dict):
    """
    Define the update function which lets you configure how your connector fetches data.
    See the technical reference documentation for more details on the update function:
    https://fivetran.com/docs/connectors/connector-sdk/technical-reference#update
    Args:
        configuration: a dictionary that holds the configuration settings for the connector.
        state: a dictionary that holds the state of the connector.
    """
    log.warning("Example: API Connector : Goshippo Shipments Connector")

    api_token = configuration.get("api_token")
    last_sync_time = state.get("last_sync_time")

    log.info(f"Starting sync with last_sync_time: {last_sync_time}")

    try:
        new_sync_time = sync_shipments(api_token, last_sync_time)

        new_state = {"last_sync_time": new_sync_time}
        # Save the progress by checkpointing the state. This is important for ensuring that the sync process can resume
        # from the correct position in case of next sync or interruptions.
        # Learn more about how and where to checkpoint by reading our best practices documentation
        # (https://fivetran.com/docs/connectors/connector-sdk/best-practices#largedatasetrecommendation).
        op.checkpoint(new_state)

        log.info(f"Sync completed successfully. New sync time: {new_sync_time}")

    except Exception as e:
        log.severe(f"Failed to sync data: {str(e)}")
        raise RuntimeError(f"Failed to sync data: {str(e)}")


def sync_shipments(api_token, last_sync_time):
    """
    Fetch shipments from Goshippo API with incremental sync support.
    Args:
        api_token: The API token for authentication.
        last_sync_time: ISO format timestamp to filter shipments updated after this time.
    Returns:
        str: The latest object_updated timestamp from synced shipments.
    """
    page_token = None
    has_more_data = True
    new_sync_time = last_sync_time
    records_processed = 0
    page_count = 0

    while has_more_data:
        page_count += 1
        log.info(f"Fetching page {page_count} of shipments")

        shipments_data = fetch_shipments_page(api_token, page_token, last_sync_time)

        if not shipments_data or "results" not in shipments_data:
            log.warning("No shipments data returned from API")
            break

        results = shipments_data.get("results", [])

        if not results:
            log.info("No more shipments to process")
            break

        for shipment in results:
            shipment_updated = shipment.get("object_updated")

            # Client-side filtering for incremental sync since API doesn't support filtering
            if last_sync_time and shipment_updated and shipment_updated <= last_sync_time:
                continue

            process_shipment(shipment)

            if shipment_updated and (new_sync_time is None or shipment_updated > new_sync_time):
                new_sync_time = shipment_updated

            records_processed += 1

            if records_processed % __CHECKPOINT_INTERVAL == 0:
                checkpoint_state = {"last_sync_time": new_sync_time}
                # Save the progress by checkpointing the state. This is important for ensuring that the sync process can resume
                # from the correct position in case of next sync or interruptions.
                # Learn more about how and where to checkpoint by reading our best practices documentation
                # (https://fivetran.com/docs/connectors/connector-sdk/best-practices#largedatasetrecommendation).
                op.checkpoint(checkpoint_state)
                log.info(f"Checkpointed after processing {records_processed} records")

        next_url = shipments_data.get("next")
        if next_url:
            page_token = extract_page_token(next_url)
            has_more_data = True
        else:
            has_more_data = False

    log.info(f"Total records processed: {records_processed}")
    return new_sync_time or last_sync_time


def fetch_shipments_page(api_token, page_token, last_sync_time):
    """
    Fetch a single page of shipments from the Goshippo API with retry logic.
    Args:
        api_token: The API token for authentication.
        page_token: The page token for pagination (None for first page).
        last_sync_time: ISO format timestamp to filter shipments.
    Returns:
        dict: JSON response containing shipment data.
    """
    url = f"{__BASE_URL}/shipments"
    headers = build_headers(api_token)
    params = build_query_params(page_token)

    for attempt in range(__MAX_RETRIES):
        try:
            response = requests.get(
                url, headers=headers, params=params, timeout=__REQUEST_TIMEOUT_SECONDS
            )
            handle_response_status(response, attempt)
            return response.json()

        except (requests.Timeout, requests.ConnectionError) as e:
            handle_request_exception(e, attempt)

    raise RuntimeError("Failed to fetch shipments after all retry attempts")


def handle_response_status(response, attempt):
    """
    Handle HTTP response status codes with retry logic for transient errors.
    Args:
        response: The HTTP response object.
        attempt: Current retry attempt number.
    """
    if response.status_code == 200:
        return

    if response.status_code in [429, 500, 502, 503, 504]:
        if attempt < __MAX_RETRIES - 1:
            delay = calculate_retry_delay(attempt)
            log.warning(
                f"Request failed with status {response.status_code}, retrying in {delay}s (attempt {attempt + 1}/{__MAX_RETRIES})"
            )
            time.sleep(delay)
            return
        else:
            error_message = (
                f"Failed after {__MAX_RETRIES} attempts. Status: {response.status_code}"
            )
            log.severe(error_message)
            raise RuntimeError(error_message)
    else:
        error_message = f"API returned status {response.status_code}: {response.text}"
        log.severe(error_message)
        raise RuntimeError(error_message)


def handle_request_exception(exception, attempt):
    """
    Handle request exceptions with retry logic.
    Args:
        exception: The exception that was raised.
        attempt: Current retry attempt number.
    """
    exception_name = type(exception).__name__
    if attempt < __MAX_RETRIES - 1:
        delay = calculate_retry_delay(attempt)
        log.warning(
            f"{exception_name}, retrying in {delay}s (attempt {attempt + 1}/{__MAX_RETRIES})"
        )
        time.sleep(delay)
    else:
        log.severe(f"{exception_name} after {__MAX_RETRIES} attempts")
        raise


def process_shipment(shipment):
    """
    Process a single shipment and upsert it along with related data.
    Args:
        shipment: The shipment data dictionary.
    """
    shipment_record = flatten_shipment(shipment)

    # The 'upsert' operation is used to insert or update data in the destination table.
    # The first argument is the name of the destination table.
    # The second argument is a dictionary containing the record to be upserted.
    op.upsert(table="shipments", data=shipment_record)

    rates = shipment.get("rates", [])
    process_rates(rates, shipment.get("object_id"))

    parcels = shipment.get("parcels", [])
    process_parcels(parcels, shipment.get("object_id"))

    messages = shipment.get("messages", [])
    process_messages(messages, shipment.get("object_id"))


def flatten_shipment(shipment):
    """
    Flatten shipment object for the main shipments table.
    Args:
        shipment: The shipment data dictionary.
    Returns:
        dict: Flattened shipment record.
    """
    flattened = {
        "object_id": shipment.get("object_id"),
        "object_created": shipment.get("object_created"),
        "object_updated": shipment.get("object_updated"),
        "object_owner": shipment.get("object_owner"),
        "status": shipment.get("status"),
        "metadata": shipment.get("metadata"),
        "shipment_date": shipment.get("shipment_date"),
        "test": shipment.get("test"),
        "order": shipment.get("order"),
        "carrier_accounts": (
            json.dumps(shipment.get("carrier_accounts", []))
            if shipment.get("carrier_accounts")
            else None
        ),
        "customs_declaration": shipment.get("customs_declaration"),
        "alternate_address_to": (
            json.dumps(shipment.get("alternate_address_to"))
            if shipment.get("alternate_address_to")
            else None
        ),
    }

    address_from = shipment.get("address_from", {})
    if isinstance(address_from, dict):
        flattened.update(
            {
                "from_name": address_from.get("name"),
                "from_company": address_from.get("company"),
                "from_street1": address_from.get("street1"),
                "from_city": address_from.get("city"),
                "from_state": address_from.get("state"),
                "from_zip": address_from.get("zip"),
                "from_country": address_from.get("country"),
                "from_phone": address_from.get("phone"),
                "from_email": address_from.get("email"),
            }
        )

    address_to = shipment.get("address_to", {})
    if isinstance(address_to, dict):
        flattened.update(
            {
                "to_name": address_to.get("name"),
                "to_company": address_to.get("company"),
                "to_street1": address_to.get("street1"),
                "to_city": address_to.get("city"),
                "to_state": address_to.get("state"),
                "to_zip": address_to.get("zip"),
                "to_country": address_to.get("country"),
                "to_phone": address_to.get("phone"),
                "to_email": address_to.get("email"),
            }
        )

    address_return = shipment.get("address_return", {})
    if isinstance(address_return, dict):
        flattened.update(
            {
                "return_name": address_return.get("name"),
                "return_company": address_return.get("company"),
                "return_street1": address_return.get("street1"),
                "return_city": address_return.get("city"),
                "return_state": address_return.get("state"),
                "return_zip": address_return.get("zip"),
                "return_country": address_return.get("country"),
                "return_phone": address_return.get("phone"),
                "return_email": address_return.get("email"),
            }
        )

    return flattened


def process_rates(rates, shipment_object_id):
    """
    Process and upsert shipment rates to the rates table.
    Args:
        rates: List of rate objects.
        shipment_object_id: The parent shipment object ID.
    """
    if not rates:
        return

    for rate in rates:
        if isinstance(rate, dict):
            rate_record = {
                "rate_object_id": rate.get("object_id"),
                "shipment_object_id": shipment_object_id,
                "amount": rate.get("amount"),
                "currency": rate.get("currency"),
                "provider": rate.get("provider"),
                "servicelevel_name": (
                    rate.get("servicelevel", {}).get("name")
                    if isinstance(rate.get("servicelevel"), dict)
                    else None
                ),
                "servicelevel_token": (
                    rate.get("servicelevel", {}).get("token")
                    if isinstance(rate.get("servicelevel"), dict)
                    else None
                ),
                "estimated_days": rate.get("estimated_days"),
                "duration_terms": rate.get("duration_terms"),
                "carrier_account": rate.get("carrier_account"),
                "object_created": rate.get("object_created"),
            }

            # The 'upsert' operation is used to insert or update data in the destination table.
            # The first argument is the name of the destination table.
            # The second argument is a dictionary containing the record to be upserted.
            op.upsert(table="shipment_rates", data=rate_record)


def process_parcels(parcels, shipment_object_id):
    """
    Process and upsert shipment parcels to the parcels table.
    Args:
        parcels: List of parcel objects.
        shipment_object_id: The parent shipment object ID.
    """
    if not parcels:
        return

    for parcel in parcels:
        if isinstance(parcel, dict):
            parcel_record = {
                "parcel_object_id": parcel.get("object_id"),
                "shipment_object_id": shipment_object_id,
                "length": parcel.get("length"),
                "width": parcel.get("width"),
                "height": parcel.get("height"),
                "distance_unit": parcel.get("distance_unit"),
                "weight": parcel.get("weight"),
                "mass_unit": parcel.get("mass_unit"),
                "metadata": parcel.get("metadata"),
                "object_created": parcel.get("object_created"),
                "object_updated": parcel.get("object_updated"),
            }

            # The 'upsert' operation is used to insert or update data in the destination table.
            # The first argument is the name of the destination table.
            # The second argument is a dictionary containing the record to be upserted.
            op.upsert(table="shipment_parcels", data=parcel_record)


def process_messages(messages, shipment_object_id):
    """
    Process and upsert shipment messages to the messages table.
    Args:
        messages: List of message objects.
        shipment_object_id: The parent shipment object ID.
    """
    if not messages:
        return

    for idx, message in enumerate(messages):
        if isinstance(message, dict):
            # Generate a unique message ID by combining shipment ID and index
            message_id = f"{shipment_object_id}_{idx}"

            message_record = {
                "message_id": message_id,
                "shipment_object_id": shipment_object_id,
                "source": message.get("source"),
                "code": message.get("code"),
                "text": message.get("text"),
            }

            # The 'upsert' operation is used to insert or update data in the destination table.
            # The first argument is the name of the destination table.
            # The second argument is a dictionary containing the record to be upserted.
            op.upsert(table="shipment_messages", data=message_record)


def build_headers(api_token):
    """
    Build HTTP headers for Goshippo API requests.
    Args:
        api_token: The API token for authentication.
    Returns:
        dict: HTTP headers dictionary.
    """
    return {
        "Authorization": f"ShippoToken {api_token}",
        "Accept": "application/json",
        "Content-Type": "application/json",
    }


def build_query_params(page_token):
    """
    Build query parameters for API requests.
    Args:
        page_token: The page token for pagination (None for first page).
    Returns:
        dict: Query parameters dictionary.
    """
    params = {"results": min(__PAGE_SIZE, __MAX_PAGE_SIZE)}

    if page_token:
        params["page_token"] = page_token

    return params


def extract_page_token(next_url):
    """
    Extract the page_token parameter from the next URL.
    Args:
        next_url: The URL containing the page_token parameter.
    Returns:
        str: The page token value or None.
    """
    if not next_url:
        return None

    try:
        from urllib.parse import urlparse, parse_qs

        parsed = urlparse(next_url)
        params = parse_qs(parsed.query)
        return params.get("page_token", [None])[0]
    except Exception as e:
        log.warning(f"Failed to extract page_token from URL: {str(e)}")
        return None


def calculate_retry_delay(attempt):
    """
    Calculate exponential backoff delay for retry attempts.
    Args:
        attempt: The current attempt number (0-indexed).
    Returns:
        int: Delay in seconds.
    """
    return min(60, __BASE_DELAY_SECONDS * (2**attempt))


# Create the connector object using the schema and update functions
connector = Connector(update=update, schema=schema)

# Check if the script is being run as the main module.
# This is Python's standard entry method allowing your script to be run directly from the command line or IDE 'run' button.
# This is useful for debugging while you write your code. Note this method is not called by Fivetran when executing your connector in production.
# Please test using the Fivetran debug command prior to finalizing and deploying your connector.
if __name__ == "__main__":
    # Open the configuration.json file and load its contents
    with open("configuration.json", "r") as f:
        configuration = json.load(f)

    # Test the connector locally
    connector.debug(configuration=configuration)
